{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN: Predict NTL and Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "import logging, os \n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import config as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function_s2(proto):\n",
    "    \n",
    "    ## Define Features\n",
    "    keys_to_features = {'viirs_ntl_group': tf.io.FixedLenFeature([], tf.int64),\n",
    "                        'b_rgb': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "    #### Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    single_ms_bands = ['b_ndvi', 'b_nir', 'b_B5', 'b_B7', 'b_B8A', 'b_B11', 'b_B12', 'b_AOT']\n",
    "    rgb_band = 'b_rgb'\n",
    "    ntl_band = 'b_ntl'\n",
    "\n",
    "    #### Parse numpy arrays and stack single bands\n",
    "    ## NTL\n",
    "    #parsed_features['b_ntl'] = tf.io.decode_png(parsed_features['b_ntl'], dtype=tf.dtypes.uint16)\n",
    "    #parsed_features['b_ntl'] = tf.io.parse_tensor(parsed_features['b_ntl'], out_type=tf.float64)\n",
    "    #parsed_features['b_ntl'] = tf.cast(parsed_features['b_ntl'], dtype = tf.float16) # tf.repeat requires float\n",
    "    #parsed_features['b_ntl'] = tf.repeat(parsed_features['b_ntl'], 3, 2)\n",
    "    # random_brightness\n",
    "    # random_contrast\n",
    "\n",
    "    ## RGB\n",
    "    parsed_features['b_rgb'] = tf.io.decode_png(parsed_features['b_rgb'], dtype=tf.dtypes.uint16)\n",
    "    parsed_features['b_rgb'] = parsed_features['b_rgb'] / 10000 # within 0 and 1\n",
    "    parsed_features['b_rgb'] = tf.image.random_flip_left_right(parsed_features['b_rgb'])\n",
    "    parsed_features['b_rgb'] = tf.image.random_flip_up_down(parsed_features['b_rgb'])\n",
    "\n",
    "    ## Single MS Bands\n",
    "    #for band_i in single_ms_bands:\n",
    "    #  parsed_features[band_i] = tf.io.decode_png(parsed_features[band_i], dtype=tf.dtypes.uint16)\n",
    "    #  parsed_features[band_i] = tf.cast(parsed_features[band_i], dtype = tf.float16) # tf.repeat requires float\n",
    "    #  parsed_features[band_i] = tf.repeat(parsed_features[band_i], 3, 2)\n",
    "\n",
    "    #return parsed_features[\"asset_pca_1\"], parsed_features['b_rgb'], parsed_features['b_ntl'], parsed_features['b_ndvi']\n",
    "    \n",
    "    # FOR CONTINUOUS\n",
    "    #return parsed_features['b_rgb'], parsed_features[\"viirs_ntl_group\"]\n",
    "\n",
    "    # FOR DISCRETE; hard coded number of classes\n",
    "    return parsed_features['b_rgb'], tf.one_hot(parsed_features[\"viirs_ntl_group\"], 3)\n",
    "\n",
    "def create_dataset(filepath):\n",
    "\n",
    "    # https://gist.github.com/Smokrow/2df26111248fa327547801ac14bb9cac\n",
    "    \n",
    "    # This works with arrays as well\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_function_s2, num_parallel_calls=8)\n",
    "    #dataset = dataset.map(_parse_function_s2_multiple, num_parallel_calls=8)\n",
    "\n",
    "    # This dataset will go on forever\n",
    "    #dataset = dataset.repeat()\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    \n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    #b_rgb, asset_pca_1 = next(iter(dataset))\n",
    "\n",
    "    # Stack single band images\n",
    "    #b_ntl = tf.repeat(b_ntl, 3, -1)\n",
    "    #b_ndvi = tf.repeat(b_ndvi, 3, -1)\n",
    "\n",
    "    # Create an iterator\n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create your tf representation of the iterator\n",
    "    #asset_pca_1, b_rgb, b_ntl, b_ndvi, = iterator.get_next()\n",
    "\n",
    "    # Bring your picture back in shape\n",
    "    #image = tf.reshape(image, [-1, 256, 256, 1])\n",
    "    \n",
    "    # Create a one hot array for your labels\n",
    "    #label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    #return asset_pca_1, b_rgb, b_ntl, b_ndvi\n",
    "    #return b_rgb, asset_pca_1\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UID\n",
    "def decode_fn_uid(record_bytes):\n",
    "    return tf.io.parse_single_example(\n",
    "      # Data\n",
    "      record_bytes,\n",
    "\n",
    "      # Schema\n",
    "      {\"uid\": tf.io.FixedLenFeature([], dtype=tf.string)}\n",
    "  )\n",
    "\n",
    "def extract_uid(TF_FILES):\n",
    "    actual_values = []\n",
    "    for batch in tf.data.TFRecordDataset([TF_FILES]).map(decode_fn_uid):\n",
    "        value = batch['uid'].numpy()\n",
    "        actual_values.append(value)\n",
    "\n",
    "    return actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_NAME = \"DHS\"\n",
    "SATELLITE = \"l8\"\n",
    "\n",
    "#### Parameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load CNN Model\n",
    "name_suffix = SATELLITE + \"_\" + 'rgb'\n",
    "\n",
    "CNN_MODEL_PATH = os.path.join(cf.GOOGLEDRIVE_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData',\n",
    "                              'cnn_models', \n",
    "                              'model_' + name_suffix + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(CNN_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load TFRecords\n",
    "\n",
    "TF_DIR = os.path.join(cf.GOOGLEDRIVE_DIRECTORY, \n",
    "                      'Data', \n",
    "                      SURVEY_NAME, \n",
    "                      'FinalData',\n",
    "                      'Individual Datasets',\n",
    "                      'cnn_' + SATELLITE,\n",
    "                      'tfrecords')\n",
    "\n",
    "TF_FILES = os.listdir(TF_DIR)\n",
    "\n",
    "TF_FILES = [string for string in TF_FILES if \".tfrecord\" in string]\n",
    "\n",
    "TF_FILES = [os.path.join(TF_DIR, x) for x in TF_FILES]\n",
    "\n",
    "#TF_FILES = TF_FILES[0:2]\n",
    "\n",
    "all_dataset = create_dataset(TF_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab features\n",
    "feature_extractor = Model(inputs=model.inputs,\n",
    "                  outputs=model.get_layer(name='fc1').output,)\n",
    "\n",
    "features = feature_extractor.predict(all_dataset)\n",
    "features_df = pd.DataFrame(features).add_prefix('cnn_feat_')\n",
    "features_df['uid'] = extract_uid(TF_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(os.path.join(cf.DROPBOX_DIRECTORY,\n",
    "                               'Data',\n",
    "                               SURVEY_NAME,\n",
    "                               'FinalData',\n",
    "                               'Individual Datasets',\n",
    "                               'cnn_features',\n",
    "                               'cnn_features_' + SATELLITE + '_rgb.csv'),\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
