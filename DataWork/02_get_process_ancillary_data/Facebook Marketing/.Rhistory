dplyr::select(country_iso2, estimate_mau_1) %>%
dplyr::rename(iso2 = country_iso2,
fb_country_mau = estimate_mau_1)
wdi_df <- readRDS(file.path(data_dir, "WDI", "FinalData", "wdi.Rds")) %>%
dplyr::select(iso2, wdi_population)
df <- df %>%
dplyr::left_join(wp_2km, by = "uid") %>%
dplyr::left_join(wp_5km, by = "uid") %>%
dplyr::left_join(wp_10km, by = "uid") %>%
dplyr::left_join(fb_country_mau, by = "iso2") %>%
dplyr::left_join(wdi_df, by = "iso2")
head(df)
# Facebook Marketing API: Scrape Data
# DESCRIPTION: Scrape data from Facebook's Marketing API at survey locations.
# Extract DAU and MAU across a variety of parameters. Code loops through survey
# locations and scrapes data across multiple parameters for that survey location.
# Because of the API rate limits, this code can take a while (weeks). Consequently,
# a data file is saved for each survey location; this allows the code to easily
# check the locations where data has already been scraped and to skip those
# locations. Another code file appends all these files into one file.
# RATE LIMIT: 200 calls/hour
# 60*60/200
# RESOURCES
# https://developers.facebook.com/docs/marketing-api/audiences/reference/basic-targeting
# https://developers.facebook.com/docs/marketing-api/audiences/reference/advanced-targeting
# https://github.com/SofiaG1l/Using_Facebook_API
# https://worldbank.github.io/connectivity_mapping/intro.html
# Load Coordinates -------------------------------------------------------------
df <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets", "survey_socioeconomic.Rds"))
if(SURVEY_NAME %in% "DHS"){
df <- df[df$most_recent_survey %in% T,]
}
if(SURVEY_NAME %in% "OPM"){
df <- df %>%
distinct(uid, .keep_all = T)
}
# Setup Credentials ------------------------------------------------------------
api_keys <- read.csv(file.path(api_key_dir, "api_keys.csv"), stringsAsFactors=F) %>%
filter(Service == "facebook_marketing_ad")
KEYS_ACCOUNTS <- api_keys$Details %>% unique()
N_KEYS <- length(KEYS_ACCOUNTS)
# Load Parameters to Scrape ----------------------------------------------------
parameters_df <- readRDS(file.path(data_dir, "Facebook Marketing", "FinalData", "facebook_marketing_parameters.Rds"))
# Determine Search Radius ------------------------------------------------------
wp_2km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
"satellite_data_from_gee",
"worldpop2020_2000_ubuff2000_rbuff2000.Rds")) %>%
dplyr::rename(wp_2km = sum) %>%
dplyr::select(-year)
wp_5km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
"satellite_data_from_gee",
"worldpop2020_5000_ubuff5000_rbuff5000.Rds")) %>%
dplyr::rename(wp_5km = sum) %>%
dplyr::select(-year)
wp_10km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
"satellite_data_from_gee",
"worldpop2020_10000_ubuff10000_rbuff10000.Rds")) %>%
dplyr::rename(wp_10km = sum) %>%
dplyr::select(-year)
fb_country_mau <- readRDS(file.path(fb_marketing_dir,  "FinalData", "country_level_mau",
"Individual Datasets",
"country_level_mau.Rds")) %>%
dplyr::select(country_iso2, estimate_mau_1) %>%
dplyr::rename(iso2 = country_iso2,
fb_country_mau = estimate_mau_1)
wdi_df <- readRDS(file.path(data_dir, "WDI", "FinalData", "wdi.Rds")) %>%
dplyr::select(iso2, wdi_population)
df <- df %>%
dplyr::left_join(wp_2km, by = "uid") %>%
dplyr::left_join(wp_5km, by = "uid") %>%
dplyr::left_join(wp_10km, by = "uid") %>%
dplyr::left_join(fb_country_mau, by = "iso2") %>%
dplyr::left_join(wdi_df, by = "iso2") %>%
dplyr::mutate(fb_penetration = fb_country_mau/wdi_population)
df$fb_penetration
df %>% distinct(country_name, fb_penetration)
df %>% distinct(country_name, fb_penetration) %>% View()
df %>% distinct(country_name, fb_penetration) %>% View()
df <- df %>%
dplyr::mutate(wp_2km = wp_2km * fb_penetration,
wp_5km = wp_5km * fb_penetration,
wp_10km = wp_10km * fb_penetration)
df$wp_2km
df$wp_2km > 1000
source("~/Documents/Github/Pakistan-Poverty-from-Sky/DataWork/02_get_process_ancillary_data/Facebook Marketing/04_scrape_fb.R")
table(df$wp_2km > 1000)
table(df$wp_2km > 1000)
table(df$wp_2km > 1000)
# Facebook Marketing API: Scrape Data
# DESCRIPTION: Scrape data from Facebook's Marketing API at survey locations.
# Extract DAU and MAU across a variety of parameters. Code loops through survey
# locations and scrapes data across multiple parameters for that survey location.
# Because of the API rate limits, this code can take a while (weeks). Consequently,
# a data file is saved for each survey location; this allows the code to easily
# check the locations where data has already been scraped and to skip those
# locations. Another code file appends all these files into one file.
# RATE LIMIT: 200 calls/hour
# 60*60/200
# RESOURCES
# https://developers.facebook.com/docs/marketing-api/audiences/reference/basic-targeting
# https://developers.facebook.com/docs/marketing-api/audiences/reference/advanced-targeting
# https://github.com/SofiaG1l/Using_Facebook_API
# https://worldbank.github.io/connectivity_mapping/intro.html
# Load Coordinates -------------------------------------------------------------
df <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets", "survey_socioeconomic.Rds"))
if(SURVEY_NAME %in% "DHS"){
df <- df[df$most_recent_survey %in% T,]
}
if(SURVEY_NAME %in% "OPM"){
df <- df %>%
distinct(uid, .keep_all = T)
}
# Setup Credentials ------------------------------------------------------------
api_keys <- read.csv(file.path(api_key_dir, "api_keys.csv"), stringsAsFactors=F) %>%
filter(Service == "facebook_marketing_ad")
KEYS_ACCOUNTS <- api_keys$Details %>% unique()
N_KEYS <- length(KEYS_ACCOUNTS)
# Load Parameters to Scrape ----------------------------------------------------
parameters_df <- readRDS(file.path(data_dir, "Facebook Marketing", "FinalData", "facebook_marketing_parameters.Rds"))
# Determine Search Radius ------------------------------------------------------
# wp_2km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
#                             "satellite_data_from_gee",
#                             "worldpop2020_2000_ubuff2000_rbuff2000.Rds")) %>%
#   dplyr::rename(wp_2km = sum) %>%
#   dplyr::select(-year)
#
# wp_5km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
#                             "satellite_data_from_gee",
#                             "worldpop2020_5000_ubuff5000_rbuff5000.Rds")) %>%
#   dplyr::rename(wp_5km = sum) %>%
#   dplyr::select(-year)
#
# wp_10km <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets",
#                              "satellite_data_from_gee",
#                              "worldpop2020_10000_ubuff10000_rbuff10000.Rds")) %>%
#   dplyr::rename(wp_10km = sum) %>%
#   dplyr::select(-year)
#
# fb_country_mau <- readRDS(file.path(fb_marketing_dir,  "FinalData", "country_level_mau",
#                                     "Individual Datasets",
#                                     "country_level_mau.Rds")) %>%
#   dplyr::select(country_iso2, estimate_mau_1) %>%
#   dplyr::rename(iso2 = country_iso2,
#                 fb_country_mau = estimate_mau_1)
#
# wdi_df <- readRDS(file.path(data_dir, "WDI", "FinalData", "wdi.Rds")) %>%
#   dplyr::select(iso2, wdi_population)
#
# df <- df %>%
#   dplyr::left_join(wp_2km, by = "uid") %>%
#   dplyr::left_join(wp_5km, by = "uid") %>%
#   dplyr::left_join(wp_10km, by = "uid") %>%
#   dplyr::left_join(fb_country_mau, by = "iso2") %>%
#   dplyr::left_join(wdi_df, by = "iso2") %>%
#   dplyr::mutate(fb_penetration = fb_country_mau/wdi_population)
#
# df <- df %>%
#   dplyr::mutate(wp_2km = wp_2km * fb_penetration,
#                 wp_5km = wp_5km * fb_penetration,
#                 wp_10km = wp_10km * fb_penetration)
#
# table(df$wp_2km > 1000)
#
# df$wp_2km[df$urban_rural %in% "R"] %>% summary()
# df$wp_2km[df$urban_rural %in% "U"] %>% summary()
# Determine Sleep Time ---------------------------------------------------------
# Determine time to pause when scraping the API due to API rate limits.
#### Pause after scrape each parameter
sleep_time_after_param <- 0
#### Pause after each location
number_locs_per_hour <- ceiling(200/nrow(parameters_df))
seconds_in_hour <- 60*60
sleep_time_after_loc <- (seconds_in_hour/number_locs_per_hour)
sleep_time_after_loc <- sleep_time_after_loc - nrow(parameters_df)*sleep_time_after_param
sleep_time_after_loc <- sleep_time_after_loc - 105
sleep_time_after_loc <- sleep_time_after_loc / N_KEYS
# Implement Function and Export ------------------------------------------------
## Grab country codes
country_code_all <- df$country_code %>% unique()
# Repeat in case missed some due to error, so will go back and check
country_code_all_rep <- c(country_code_all,
country_code_all,
country_code_all,
country_code_all,
country_code_all) %>%
sort()
## UIDs to scrape
KEY_i  <- 1
#### Loop over countries
country_code_i = country_code_all_rep[1]
print(country_code_i)
df_c <- df[df$country_code %in% country_code_i,]
country_uids <- unique(df_c$uid) %>% as.character()
uid_i = country_uids[1]
df_i <- df_c[df_c$uid %in% uid_i,]
OUT_PATH <- file.path(dropbox_dir, "Data", SURVEY_NAME,  "FinalData", "Individual Datasets",
"fb_mau_individual_datasets", paste0("fb_",uid_i,"_radius",RADIUS_KM,"km.Rds"))
RADIUS_KM=10
## Set keys
print(KEY_i)
account_i <- KEYS_ACCOUNTS[KEY_i]
api_keys_i <- api_keys[api_keys$Details %in% account_i,]
token <- api_keys_i$Key[api_keys_i$Account %in% "token"] %>% str_squish()
creation_act <- api_keys_i$Key[api_keys_i$Account %in% "creation_act"] %>% str_replace_all("ACT_", "") %>% str_squish()
version <- api_keys_i$Key[api_keys_i$Account %in% "version"] %>% str_squish()
## Scape
print(account_i)
radius_2km <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 2,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
parameters_df_i <- parameters_df[1,]
radius_2km <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 2,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
radius_2km
unique(param_i)
nrow(parameters_df)
rep(NA, nrow(parameters_df))
# Still grab to determine whether need to scrape
radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 10,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
radius_Xkm
fb_df <- data.frame(uid = rep(df_i$uid, nrow(parameters_df)))
fb_df
query_fb_marketing_api
radius_Xkm$estimate_mau
radius_Xkm$estimate_maua
asdsadasd
adsasdsad$adasdsad
is.null(adsasdsad$adasdsad)
fb_df <- data.frame(uid = rep(df_i$uid, nrow(parameters_df)))
fb_df$estimate_mau <- 1000
fb_df$estimate_mau_lower_bound <- 1000
fb_df$estimate_mau_upper_bound <- 1000
fb_df$location_type <- "coordinates"
fb_df$latitude <- df_i$latitude
fb_df$longitude <- df_i$longitude
fb_df$radius <- radius
fb_df$radius_unit <- "kilometer"
fb_df$param_id <- 1:nrow(parameters_df)
fb_df
## Set keys
print(KEY_i)
account_i <- KEYS_ACCOUNTS[KEY_i]
api_keys_i <- api_keys[api_keys$Details %in% account_i,]
token <- api_keys_i$Key[api_keys_i$Account %in% "token"] %>% str_squish()
creation_act <- api_keys_i$Key[api_keys_i$Account %in% "creation_act"] %>% str_replace_all("ACT_", "") %>% str_squish()
version <- api_keys_i$Key[api_keys_i$Account %in% "version"] %>% str_squish()
## Scape
print(account_i)
# Determine Radius -------------------------------------------------------
parameters_df_i <- parameters_df[1,]
radius <- NA
#### Check 2km
fb_radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 2,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
if(is.null(fb_radius_Xkm)){
radius <- 2
} else{
if(radius_2km$estimate_mau >= 2000){
radius <- 2
}
#### Check 5km
if(is.na(radius)){
radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 5,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
if(radius_5km$estimate_mau >= 2000){
radius <- 5
}
}
#### Check 10km
if(is.na(radius)){
# Still grab to determine whether need to scrape
radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 10,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 1)
radius <- 10
}
}
radius
# Determine if need to scrape --------------------------------------------
SCRAPE_ALL_DATA <- TRUE
if(!is.null(fb_radius_Xkm)){
if(!is.null(radius_Xkm$estimate_mau)){
if(radius_Xkm$estimate_mau %in% 1000){
print("estimate_1_mau = 1000; assigning 1000 to all params")
fb_df <- data.frame(uid = rep(df_i$uid, nrow(parameters_df)))
fb_df$estimate_mau <- 1000
fb_df$estimate_mau_lower_bound <- 1000
fb_df$estimate_mau_upper_bound <- 1000
fb_df$location_type <- "coordinates"
fb_df$latitude <- df_i$latitude
fb_df$longitude <- df_i$longitude
fb_df$radius <- radius
fb_df$radius_unit <- "kilometer"
fb_df$param_id <- 1:nrow(parameters_df)
SCRAPE_ALL_DATA <- FALSE
}
}
}
SCRAPE_ALL_DATA
query_fb_marketing_api
radius_Xkm
radius_Xkm$ERROR %>% is.null()
query_fb_marketing_api
print("estimate_1_mau = invalid location; assigning NA to all params")
fb_df <- data.frame(uid = rep(df_i$uid, nrow(parameters_df)))
fb_df$estimate_mau <- NA
fb_df$estimate_mau_lower_bound <- NA
fb_df$estimate_mau_upper_bound <- NA
fb_df$location_type <- "coordinates"
fb_df$latitude <- df_i$latitude
fb_df$longitude <- df_i$longitude
fb_df$param_id <- 1:nrow(parameters_df)
fb_df
fb_df <- data.frame(uid = rep(df_i$uid, nrow(parameters_df)))
fb_df$ERROR <- "Incorrect Location Format"
fb_df$param_id <- 1:nrow(parameters_df)
# Facebook Marketing API: Scrape Data
# DESCRIPTION: Scrape data from Facebook's Marketing API at survey locations.
# Extract DAU and MAU across a variety of parameters. Code loops through survey
# locations and scrapes data across multiple parameters for that survey location.
# Because of the API rate limits, this code can take a while (weeks). Consequently,
# a data file is saved for each survey location; this allows the code to easily
# check the locations where data has already been scraped and to skip those
# locations. Another code file appends all these files into one file.
# RATE LIMIT: 200 calls/hour
# 60*60/200
# RESOURCES
# https://developers.facebook.com/docs/marketing-api/audiences/reference/basic-targeting
# https://developers.facebook.com/docs/marketing-api/audiences/reference/advanced-targeting
# https://github.com/SofiaG1l/Using_Facebook_API
# https://worldbank.github.io/connectivity_mapping/intro.html
# Load Coordinates -------------------------------------------------------------
df <- readRDS(file.path(data_dir, SURVEY_NAME, "FinalData", "Individual Datasets", "survey_socioeconomic.Rds"))
if(SURVEY_NAME %in% "DHS"){
df <- df[df$most_recent_survey %in% T,]
}
if(SURVEY_NAME %in% "OPM"){
df <- df %>%
distinct(uid, .keep_all = T)
}
# Setup Credentials ------------------------------------------------------------
api_keys <- read.csv(file.path(api_key_dir, "api_keys.csv"), stringsAsFactors=F) %>%
filter(Service == "facebook_marketing_ad")
KEYS_ACCOUNTS <- api_keys$Details %>% unique()
N_KEYS <- length(KEYS_ACCOUNTS)
# Load Parameters to Scrape ----------------------------------------------------
parameters_df <- readRDS(file.path(data_dir, "Facebook Marketing", "FinalData", "facebook_marketing_parameters.Rds"))
# Determine Sleep Time ---------------------------------------------------------
# Determine time to pause when scraping the API due to API rate limits.
#### Pause after scrape each parameter
sleep_time_after_param <- 0
#### Pause after each location
number_locs_per_hour <- ceiling(200/nrow(parameters_df))
seconds_in_hour <- 60*60
sleep_time_after_loc <- (seconds_in_hour/number_locs_per_hour)
sleep_time_after_loc <- sleep_time_after_loc - nrow(parameters_df)*sleep_time_after_param
sleep_time_after_loc <- sleep_time_after_loc - 105
sleep_time_after_loc <- sleep_time_after_loc / N_KEYS
# Implement Function and Export ------------------------------------------------
## Grab country codes
country_code_all <- df$country_code %>% unique()
# Repeat in case missed some due to error, so will go back and check
country_code_all_rep <- c(country_code_all,
country_code_all,
country_code_all,
country_code_all,
country_code_all) %>%
sort()
## UIDs to scrape
KEY_i  <- 1
#### Loop over countries
# Still grab to determine whether need to scrape
radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 10,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 0.2)
radius_Xkm
radius_Xkm <- query_fb_marketing_api(location_type = "coordinates",
latitude = df_i$latitude,
longitude = df_i$longitude,
radius = 5,
radius_unit = "kilometer",
education_statuses = parameters_df_i$education_statuses,
behavior = parameters_df_i$behavior %>% str_split(",") %>% unlist(),
interest = parameters_df_i$interest,
gender = parameters_df_i$gender %>% str_split(",") %>% unlist(),
age_min = parameters_df_i$age_min,
age_max = parameters_df_i$age_max,
version = version,
creation_act = creation_act,
token = token,
sleep_time = 0.2)
radius_Xkm
for(i in 1:10){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if(i == 3){
next
}
}
}
}
}
}
}
for(i in 1:10){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if("a" == "a"){
if(i == 3){
next
}
}
}
}
}
}
print(i)
}
