{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poverty Estimation with Facebook Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "#import rasterio\n",
    "#from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (BaggingClassifier, AdaBoostClassifier,\n",
    "                              AdaBoostRegressor,\n",
    "                              GradientBoostingClassifier, RandomForestClassifier,\n",
    "                              RandomForestRegressor,\n",
    "                             BaggingRegressor, GradientBoostingRegressor)\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                             recall_score, classification_report,\n",
    "                            r2_score, mean_absolute_error, mean_squared_error)\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import logging, os \n",
    "\n",
    "import grid_params as grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data\"\n",
    "SURVEY_NAME = \"DHS\"\n",
    "\n",
    "OUT_DIR = os.path.join(data_dir, SURVEY_NAME, 'FinalData', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robmarty/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (27,31,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fb_df = pd.read_csv(os.path.join(data_dir, SURVEY_NAME, 'FinalData', 'Individual Datasets', 'facebook_marketing_dau_mau_prop.csv'))\n",
    "survey_df = pd.read_csv(os.path.join(data_dir, SURVEY_NAME, \"FinalData\", \"Individual Datasets\", \"survey_socioeconomic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = survey_df.merge(fb_df, on = 'uid')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel_valresult(df, country, est_type, target, parameters):\n",
    "    # DESCRIPTION:\n",
    "    # ARGS:\n",
    "    # df: Dataframe\n",
    "    # country: iso2\n",
    "    # est_type: within_country or other_countries\n",
    "\n",
    "    if est_type == 'within_country':\n",
    "        df_country = df[df.country_code == country]\n",
    "        \n",
    "        id_cut = round(df_country.shape[0] / 4)\n",
    "\n",
    "        df_val = df_country.iloc[:id_cut]\n",
    "        df_traintest = df_country.iloc[id_cut:]\n",
    "        \n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    if est_type == 'other_countries':\n",
    "        df_val = df[df.country_code == country]\n",
    "        df_traintest = df[df.country_code != country]\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    if est_type == 'india':\n",
    "        df_val = df[df.country_code == country]\n",
    "        df_traintest = df[df.country_code == 'IA']\n",
    "        df_traintest.reset_index()\n",
    "        \n",
    "    # Initialize\n",
    "    kf = KFold(n_splits=5)\n",
    "    results_df = pd.DataFrame() # results iterating over params\n",
    "\n",
    "    for i in parameters['regressors']:\n",
    "        for j in parameters[i]:\n",
    "            \n",
    "            pred_dict = {\n",
    "                'regressor': i,\n",
    "                'params': j,\n",
    "                'country': country,\n",
    "                'est_type': est_type,\n",
    "                'target': target\n",
    "             }\n",
    "\n",
    "            fold = 0\n",
    "            for train_index, test_index in kf.split(df_traintest):\n",
    "                \n",
    "                # Separate into train and test\n",
    "                df_train = df_traintest.iloc[train_index]\n",
    "                df_test = df_traintest.iloc[test_index]\n",
    "\n",
    "                x_train = df_train.filter(regex='^estimate_mau_', axis=1)\n",
    "                x_test = df_test.filter(regex='^estimate_mau_', axis=1)\n",
    "\n",
    "                y_train = df_train[target]\n",
    "                y_test = df_test[target]\n",
    "\n",
    "                # Normalize\n",
    "                x_scaler = StandardScaler().fit(x_train)\n",
    "\n",
    "                x_train = x_scaler.transform(x_train)\n",
    "                x_test = x_scaler.transform(x_test)\n",
    "\n",
    "                ### Initialize regressor, fit data, then append model to list\n",
    "                regressor = eval(i)(**j)\n",
    "                trained = regressor.fit(x_train, y_train)\n",
    "\n",
    "                ### Results\n",
    "                y_pred = trained.predict(x_test)\n",
    "                \n",
    "                pred_dict['r2_score_' + str(fold)] = r2_score(y_test, y_pred)\n",
    "\n",
    "                fold += 1\n",
    "\n",
    "            results_df = results_df.append(pred_dict, ignore_index=True)\n",
    "            results_df.to_csv(os.path.join(OUT_DIR, 'indiv_param_results',\n",
    "                                           'results_' + \n",
    "                                           country + '_' +\n",
    "                                           est_type + '_' +\n",
    "                                           target + \n",
    "                                           '_fbonly.csv'))\n",
    "                  \n",
    "    # Results on validation set --------------------------------------\n",
    "    results_df['r2_score_avg'] = (results_df['r2_score_0'] + \n",
    "                              results_df['r2_score_1'] + \n",
    "                              results_df['r2_score_2'] + \n",
    "                              results_df['r2_score_3'] + \n",
    "                              results_df['r2_score_4']) / 5\n",
    "\n",
    "    results_df = results_df.sort_values(by=['r2_score_avg'], ascending=False)\n",
    "\n",
    "    results_df_best = results_df.iloc[0]\n",
    "    \n",
    "    # Results on validation set --------------------------------------    \n",
    "    x_traintest = df_traintest.filter(regex='^estimate_mau_', axis=1)\n",
    "    x_val = df_val.filter(regex='^estimate_mau_', axis=1)\n",
    "\n",
    "    # Prep X/Y\n",
    "    y_traintest = df_traintest[target]\n",
    "    y_val = df_val[target]\n",
    "\n",
    "    # Normalize\n",
    "    x_scaler = StandardScaler().fit(x_traintest)\n",
    "\n",
    "    x_traintest = x_scaler.transform(x_traintest)\n",
    "    x_val = x_scaler.transform(x_val)\n",
    "\n",
    "    # Grab regressor/parameters\n",
    "    i_best = results_df_best['regressor']\n",
    "    j_best = results_df_best['params']\n",
    "    \n",
    "    # Train model\n",
    "    regressor = eval(i_best)(**j_best)\n",
    "    trained_best = regressor.fit(x_traintest, y_traintest)\n",
    "\n",
    "    y_pred = trained.predict(x_val)\n",
    "    \n",
    "    # Results\n",
    "    valid_dict = {\n",
    "        'country': country,\n",
    "        'est_type': est_type,\n",
    "        'target': target,\n",
    "        'r2_score_traintest_avg': results_df_best['r2_score_avg'],\n",
    "        'r2_score_traintest_0': results_df_best['r2_score_0'],\n",
    "        'r2_score_traintest_1': results_df_best['r2_score_1'],\n",
    "        'r2_score_traintest_2': results_df_best['r2_score_2'],\n",
    "        'r2_score_traintest_3': results_df_best['r2_score_3'],\n",
    "        'r2_score_traintest_4': results_df_best['r2_score_4'],\n",
    "        'regressor': i_best,\n",
    "        'params': j_best,\n",
    "     }\n",
    "\n",
    "    valid_dict['r2_score_val'] = r2_score(y_val, y_pred)\n",
    "    valid_dict['N_train'] = df_traintest.shape[0]\n",
    "    valid_dict['N_val'] = df_val.shape[0]\n",
    "    \n",
    "    valid_df = pd.DataFrame() # final results\n",
    "    valid_df = valid_df.append(valid_dict, ignore_index=True)\n",
    "        \n",
    "    y_dict = {\n",
    "        'y': country,\n",
    "        'est_type': est_type,\n",
    "        'target': target,\n",
    "        'y': y_traintest,\n",
    "        'y_pred': y_pred,\n",
    "     }\n",
    "    y_df = pd.DataFrame() # final results\n",
    "    y_df = y_df.append(y_dict, ignore_index=True)\n",
    "    \n",
    "    # Predicted and true values\n",
    "    y_dict = {\n",
    "        'country': country,\n",
    "        'est_type': est_type,\n",
    "        'target': target,\n",
    "        'y': y_val,\n",
    "        'y_pred': y_pred,\n",
    "    }\n",
    "\n",
    "    y_df = pd.DataFrame.from_dict(y_dict)\n",
    "\n",
    "    return valid_df, y_df, trained_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = grids.GRID_REGRESS\n",
    "\n",
    "val_df_all = pd.DataFrame()\n",
    "ypred_df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within_country IA\n",
      "within_country BD\n",
      "within_country PK\n",
      "within_country KH\n",
      "within_country PH\n",
      "within_country TL\n",
      "within_country NP\n",
      "within_country MM\n",
      "within_country TJ\n",
      "within_country KY\n",
      "other_countries IA\n",
      "other_countries BD\n",
      "other_countries PK\n",
      "other_countries KH\n",
      "other_countries PH\n",
      "other_countries TL\n",
      "other_countries NP\n",
      "other_countries MM\n",
      "other_countries TJ\n",
      "other_countries KY\n",
      "india IA\n",
      "skip!\n",
      "india BD\n"
     ]
    }
   ],
   "source": [
    "for est_type_i in ['within_country', 'other_countries', 'india']:\n",
    "    for cc_i in df.country_code.unique():\n",
    "        print(est_type_i + ' ' + cc_i)\n",
    "        \n",
    "        if (est_type_i == 'india') & (cc_i == 'IA'):\n",
    "            print(\"skip!\")\n",
    "        else:\n",
    "            val_df_i, y_df_i, model = trainmodel_valresult(df, cc_i, est_type_i, 'asset_pca_1', parameters)\n",
    "            \n",
    "            val_df_all = val_df_all.append(val_df_i, ignore_index=True)\n",
    "            ypred_df_all = ypred_df_all.append(y_df_i, ignore_index=True)\n",
    "            \n",
    "            dump(model, os.path.join(OUT_DIR, 'models', 'fbonly_model_' + est_type_i + '_' + cc_i + '_asset_pca_1' + '.joblib'))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_all.to_csv(os.path.join(OUT_DIR, 'results_fbonly.csv'))\n",
    "ypred_df_all.to_csv(os.path.join(OUT_DIR, 'ypred_fbonly.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
