{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Binary Measure of Poverty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "#import rasterio\n",
    "#from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, RandomForestClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                             recall_score, classification_report)\n",
    "#from keras.models import load_model\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import logging, os \n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from s3fs.core import S3FileSystem \n",
    "s3 = S3FileSystem()\n",
    "role = get_execution_role()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "### User Defined Libraries ###\n",
    "import grid_params as grids\n",
    "#import config as cf\n",
    "#import feature_extraction as fe\n",
    "\n",
    "bucket = 'worldbank-pakistan-data'\n",
    "LOCAL_DIR = '/home/ec2-user/SageMaker/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(params, x_train, x_test, y_train, y_test, verbose=False):\n",
    "    '''\n",
    "    Saves a .pkl file of TrainedRegressor objects for each model type, as\n",
    "    AWS free tier server will usually not hold all 800+ objects in memory.\n",
    "\n",
    "    Input:  params - dictionary of model parameters\n",
    "            features - dataframe of feature data\n",
    "            labels - dataframe of labels\n",
    "            feature_sets - dictionary of string lists of feature names\n",
    "    Output: dataframe of training errors\n",
    "            Also saves a .pkl file of TrainedRegressor objects for each model\n",
    "    '''\n",
    "    count = 0\n",
    "\n",
    "    # Loop over models, hyperparameter combinations, and feature sets\n",
    "    # Save one set of trained models for each regressor\n",
    "    results_df = pd.DataFrame()\n",
    "    y_df = pd.DataFrame({'y': y_test})\n",
    "\n",
    "    for i in params['regressors']:\n",
    "        models = []\n",
    "        for j in params[i]:\n",
    "\n",
    "            count += 1\n",
    "            if verbose:\n",
    "                print(f'{datetime.datetime.now()} Model {count}: Training {i} with params {str(j)}')\n",
    "            try:\n",
    "                ### Initialize regressor, fit data, then append model to list\n",
    "                regressor = eval(i)(**j)\n",
    "                trained = regressor.fit(x_train, y_train)\n",
    "                #models.append(TrainedRegressor(i, str(j), k, trained))\n",
    "\n",
    "                ### Results\n",
    "                y_pred = trained.predict(x_test)\n",
    "\n",
    "                pred_dict = {\n",
    "                    'regressor': i,\n",
    "                    'params': j,\n",
    "                    'accuracy_score': accuracy_score(y_test, y_pred),\n",
    "                    'recall_score': recall_score(y_test, y_pred),\n",
    "                    'precision_score': precision_score(y_test, y_pred),\n",
    "                    'y_truth_1': sum(y_test == 1),\n",
    "                    'y_truth_0': sum(y_test == 0),\n",
    "                    'model_number': count\n",
    "                 }\n",
    "\n",
    "                results_df = results_df.append(pred_dict, ignore_index=True)\n",
    "                y_df['y_pred_' + str(count)] = y_pred\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"{datetime.datetime.now()}    ERROR: {str(e)}\")\n",
    "                training_error_df.append({\n",
    "                    'regressor': i,\n",
    "                    'params': str(j),\n",
    "                    'error_message': str(e)\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    return results_df, y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Prep Data and Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(s3.open('{}/{}'.format(bucket, os.path.join('OPM', 'FinalData', 'Merged Datasets', 'cnn_merge.csv'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>period</th>\n",
       "      <th>year</th>\n",
       "      <th>province</th>\n",
       "      <th>psu</th>\n",
       "      <th>locality</th>\n",
       "      <th>treatment</th>\n",
       "      <th>panel</th>\n",
       "      <th>present11</th>\n",
       "      <th>present13</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_feat_90</th>\n",
       "      <th>cnn_feat_91</th>\n",
       "      <th>cnn_feat_92</th>\n",
       "      <th>cnn_feat_93</th>\n",
       "      <th>cnn_feat_94</th>\n",
       "      <th>cnn_feat_95</th>\n",
       "      <th>cnn_feat_96</th>\n",
       "      <th>cnn_feat_97</th>\n",
       "      <th>cnn_feat_98</th>\n",
       "      <th>cnn_feat_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100389</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>144.314380</td>\n",
       "      <td>220.20631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.24104</td>\n",
       "      <td>309.09470</td>\n",
       "      <td>418.908400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.905373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100401</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>108.988020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>31.650860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>78.17691</td>\n",
       "      <td>69.511850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100581</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>216.650730</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>70.73168</td>\n",
       "      <td>59.625446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101101</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>129.465040</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.424894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>77.71559</td>\n",
       "      <td>67.349990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101236</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.643074</td>\n",
       "      <td>181.26860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.46274</td>\n",
       "      <td>283.18677</td>\n",
       "      <td>425.391660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.898094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  period  year  province  psu  locality  treatment  panel  present11  \\\n",
       "0  100389       2  2014         1    1         1          0      0          1   \n",
       "1  100401       2  2014         1    1         1          0      0          1   \n",
       "2  100581       2  2014         1    1         1          0      0          1   \n",
       "3  101101       2  2014         1    1         1          0      1          1   \n",
       "4  101236       2  2014         1    1         1          0      0          1   \n",
       "\n",
       "   present13  ...  cnn_feat_90  cnn_feat_91  cnn_feat_92  cnn_feat_93  \\\n",
       "0          1  ...   144.314380    220.20631     0.000000          0.0   \n",
       "1          1  ...   108.988020      0.00000    31.650860          0.0   \n",
       "2          1  ...   216.650730      0.00000     0.000000          0.0   \n",
       "3          1  ...   129.465040      0.00000     7.424894          0.0   \n",
       "4          0  ...   125.643074    181.26860     0.000000          0.0   \n",
       "\n",
       "   cnn_feat_94  cnn_feat_95  cnn_feat_96  cnn_feat_97  cnn_feat_98  \\\n",
       "0    234.24104    309.09470   418.908400          0.0          0.0   \n",
       "1      0.00000     78.17691    69.511850          0.0          0.0   \n",
       "2      0.00000     70.73168    59.625446          0.0          0.0   \n",
       "3      0.00000     77.71559    67.349990          0.0          0.0   \n",
       "4    200.46274    283.18677   425.391660          0.0          0.0   \n",
       "\n",
       "   cnn_feat_99  \n",
       "0    35.905373  \n",
       "1     0.000000  \n",
       "2     0.000000  \n",
       "3     0.000000  \n",
       "4    41.898094  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2335\n",
       "True     1037\n",
       "Name: pscores_poor, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pscores_poor'] = df.pscores <= 16.17\n",
    "df['pscores_poor_med'] = df.pscores <= df.pscores.median()\n",
    "\n",
    "df.pscores_poor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pscores_poor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pscores_poor_med\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for target in ['pscores_poor', 'pscores_poor_med']:\n",
    "\n",
    "    print(target) # Print Status\n",
    "\n",
    "    x = df.filter(regex='^cnn_', axis=1)\n",
    "    y = df[target]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE)\n",
    "\n",
    "    # Normalize\n",
    "    x_scaler = StandardScaler().fit(x_train)\n",
    "\n",
    "    x_train = x_scaler.transform(x_train)\n",
    "    x_test = x_scaler.transform(x_test)\n",
    "\n",
    "    # Train/Evaluate -------------------------------------------\n",
    "    parameters = grids.GRID_CLASS\n",
    "\n",
    "    # r_df: dataframe of results. Contains \"model_number\" variable to match with pred_df\n",
    "    # pred_df: predicted values (also contains true value). In format of y_pred_[model_number] \n",
    "    r_df, pred_df = train_models(parameters, x_train, x_test, y_train, y_test, verbose=False)\n",
    "\n",
    "    r_df['target'] = target\n",
    "    r_df.to_csv(os.path.join(LOCAL_DIR, 'results_' + str(count) + '.csv'))\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('Poverty Estimation Results', 'binary_classification', 'individual_files', 'results_' + str(count) + '.csv')).upload_file(os.path.join(LOCAL_DIR, 'results_' + str(count) + '.csv'))\n",
    "\n",
    "    pred_df['target'] = target\n",
    "    pred_df.to_csv(os.path.join(LOCAL_DIR, 'results_' + str(count) + '.csv'))\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('Poverty Estimation Results', 'binary_classification', 'predicted_values', 'results_' + str(count) + '.csv')).upload_file(os.path.join(LOCAL_DIR, 'results_' + str(count) + '.csv'))\n",
    "    \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
