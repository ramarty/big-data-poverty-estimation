{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_cnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worldbank/Pakistan-Poverty-from-Sky/blob/master/DataWork/03_predict_ntl_with_dtl/03_cnn_directly_opm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z34KtcX5Pp7o"
      },
      "source": [
        "# __Predicting NTL using DTL - Directly on Outcomes__\n",
        "\n",
        "__Code in Github:__ _/DataWork/03_predict_ntl_with_dtl/02_cnn.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vds1yHMwLJp2"
      },
      "source": [
        "## **Filepaths and Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOdgNXFG8EmH"
      },
      "source": [
        "PARAM_NAME = \"Nbands3_nNtlBins3_minNTLbinCount16861\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "206o8Vv6OjtI"
      },
      "source": [
        "# Set seeds. Note that using a GPU can still introduce randomness.\n",
        "# (also not taking into account tensorflow randomness)\n",
        "from numpy.random import seed\n",
        "seed(42)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urMUqpA_1_fM",
        "outputId": "e4da2241-c352-4f15-ab53-c873fd3053ef"
      },
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjmhWLqU95-J"
      },
      "source": [
        "#drive.flush_and_unmount()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbrNDZWq2UdD"
      },
      "source": [
        "# Filepaths\n",
        "import os, datetime\n",
        "\n",
        "DATA_DIR = os.path.join('/content/drive', 'My Drive', 'World Bank', 'Pakistan Poverty Estimation', 'Data', 'BISP', 'FinalData', 'Individual Datasets')\n",
        "\n",
        "#CNN_FILENAME = os.path.join(DATA_DIR, 'script_CNN.h5')\n",
        "#CNN_PARAMS_FILENAME = os.path.join(CNN_DIR, 'CNN_parameters.json')\n",
        "#NTL_FILENAME = os.path.join(CNN_DIR, 'ntl.npy')\n",
        "#NTL_CONT_FILENAME = os.path.join(CNN_DIR, 'ntl_continuous.npy')\n",
        "#DTL_FILENAME = os.path.join(CNN_DIR, 'dtl.npy')\n",
        "#PREDICTION_FILENAME = os.path.join(CNN_DIR, 'cnn_predictions_truth_values.csv')\n",
        "#PREDICTION_FILENAME_CONT = os.path.join(CNN_DIR, 'cnn_predictions_continuous_truth_values.csv')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G_jUHE3y_pj"
      },
      "source": [
        ""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWeveSe00gul"
      },
      "source": [
        "import os, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "import logging, os \n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5k-bEJvLVvj"
      },
      "source": [
        "## **Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkAYWJCg0gut"
      },
      "source": [
        "def transform_target(gdf, orig_target_name, n_bins):\n",
        "    '''\n",
        "    Creates log NTL variable and bins into 5 classes using k-means clutering.\n",
        "    '''\n",
        "    # Perform log(x+1) for defined domain\n",
        "    transformed_target_name = f'log_{orig_target_name}'\n",
        "    gdf[transformed_target_name] = np.log(gdf[orig_target_name] + 1)\n",
        "    # Bin target\n",
        "    target = gdf[transformed_target_name].to_numpy().reshape(-1,1)\n",
        "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='kmeans')\n",
        "    gdf[FINAL_TARGET_NAME] = discretizer.fit_transform(target)\n",
        "\n",
        "def normalize(X):\n",
        "    '''\n",
        "    Normalizes features.\n",
        "    '''\n",
        "    return X.astype('float32') / 255.0\n",
        "\n",
        "def define_model_imagenet(height, width, channels, num_classes):\n",
        "    '''\n",
        "    Defines and compiles CNN model.\n",
        "    \n",
        "    Inputs:\n",
        "        height, width, channels, num_classes (int)\n",
        "    Returns:\n",
        "        model (keras.Model object)\n",
        "    '''\n",
        "\n",
        "    # https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
        "    # https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2\n",
        "\n",
        "    #### Base model\n",
        "    input_shape = (height, width, channels)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #### Model Customization\n",
        "    # We take the last layer of our the model and add it to our classifier\n",
        "    last = base_model.layers[-1].output\n",
        "    x = Flatten()(last)\n",
        "    x = Dense(100, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "    model = Model(base_model.input, x)\n",
        "    # We compile the model\n",
        "    model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def define_model_imagenet_cont(height, width, channels, num_classes):\n",
        "    '''\n",
        "    Defines and compiles CNN model [continuous].\n",
        "    \n",
        "    Inputs:\n",
        "        height, width, channels, num_classes (int)\n",
        "    Returns:\n",
        "        model (keras.Model object)\n",
        "    '''\n",
        "\n",
        "    # https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
        "    # https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2\n",
        "\n",
        "    #### Base model\n",
        "    input_shape = (height, width, channels)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #### Model Customization\n",
        "    # We take the last layer of our the model and add it to our classifier\n",
        "    last = base_model.layers[-1].output\n",
        "    x = Flatten()(last)\n",
        "    x = Dense(100, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    #x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "    x = Dense(1, kernel_initializer='normal')(x)\n",
        "\n",
        "    model = Model(base_model.input, x)\n",
        "    # We compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, trainX, trainY, testX, testY):\n",
        "    '''\n",
        "    Fits model, evaluates model, saves best model over epochs and cross-validations.\n",
        "    \n",
        "    Inputs:\n",
        "        model (CNN model) keras.Model object\n",
        "        trainX, trainY (numpy.ndarray) 4D array of DTL features and 2D array of targets for training\n",
        "        testX, testY (numpy.ndarray) 4D array of DTL features and 2D array of targets for testing\n",
        "        current_kfold (int) iteration in kfold cross-val, default=None for no cross-val\n",
        "        display_metrics (bool) Default=False\n",
        "    Returns:\n",
        "        None\n",
        "    # https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29\n",
        "    '''\n",
        "\n",
        "    # Use early stopping to help with overfitting\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=False)\n",
        "\n",
        "    # Save best model based on accuracy\n",
        "    mc = ModelCheckpoint(CNN_FILENAME, monitor='val_loss', mode='min', \n",
        "                         verbose=True, save_best_only=True)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(trainX, trainY, \n",
        "            epochs=100, \n",
        "            batch_size=500, \n",
        "            validation_data=(testX, testY), \n",
        "            callbacks=[es, mc], \n",
        "            verbose=False)\n",
        "\n",
        "    # Show accuracy\n",
        "    loss, accuracy = model.evaluate(testX, testY, verbose=False)\n",
        "    print(f'                              Accuracy: {accuracy}')\n",
        "\n",
        "    #return model\n",
        "        \n",
        "\n",
        "def evaluate_with_crossval(model, dataX, dataY, k=2):\n",
        "    '''\n",
        "    Performs evaulation with K-fold cross validation.\n",
        "    \n",
        "    Inputs:\n",
        "        model (keras.Model object)\n",
        "        dataX, dataY (numpy.ndarray) 4D array of DTL features and 2D array of targets \n",
        "                                     for training\n",
        "        k (int)\n",
        "    Returns:\n",
        "        None\n",
        "    '''\n",
        "    # Define k-fold cross-val\n",
        "    kfold = KFold(k, shuffle=True, random_state=1)\n",
        "    # Loop through folds\n",
        "    count = 1\n",
        "    for train_idx, test_idx in kfold.split(dataX):\n",
        "        print(f'{datetime.datetime.now()}    --- Current K-fold: {count} ---')\n",
        "        # Select subsets for training and testing\n",
        "        trainX, trainY, testX, testY = dataX[train_idx], dataY[train_idx], \\\n",
        "                                       dataX[test_idx], dataY[test_idx]\n",
        "        # Pass to evaluate_model function\n",
        "        evaluate_model(model, trainX, trainY, testX, testY)\n",
        "        count += 1\n",
        "\n",
        "def display_eval_metrics(model, testX, testY, n_ntl_bins):\n",
        "    '''\n",
        "    Displays evaluation metrics for a given trained model.\n",
        "    '''\n",
        "    # Get predictions\n",
        "    predY = model.predict(testX)\n",
        "    predY = np.argmax(predY, axis = 1)\n",
        "    testY_bins = np.argmax(testY, axis = 1)\n",
        "    # Generate classification report\n",
        "    classes = ['Radiance Level %01d' %i for i in range(1,n_ntl_bins+1)]\n",
        "    print(classification_report(testY_bins, predY, target_names=classes))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lWj5moLdQW"
      },
      "source": [
        "## **Load Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7mQb5uJ6BEq",
        "outputId": "31cd1874-2d52-409c-eced-27dea3e8bca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "with open(CNN_PARAMS_FILENAME, 'r') as fp:\n",
        "    cnn_param_dict = json.load(fp)\n",
        "\n",
        "N_bands = cnn_param_dict['N_bands']\n",
        "n_ntl_bins = cnn_param_dict['n_ntl_bins']\n",
        "image_height = cnn_param_dict['image_height']\n",
        "image_width = cnn_param_dict['image_width']\n",
        "bands = cnn_param_dict['bands']\n",
        "min_ntl_bin_count = cnn_param_dict['bands']"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-7adc5a5adf3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_PARAMS_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcnn_param_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_param_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N_bands'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_ntl_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_param_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_ntl_bins'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CNN_PARAMS_FILENAME' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ0rFqCiLhM0"
      },
      "source": [
        "## **Load and Prep Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxnc2M9lzlap"
      },
      "source": [
        "#bisp_viirs = pd.read_csv(os.path.join(DATA_DIR, 'bisp_viirs.csv'))\n",
        "bisp_pov = pd.read_csv(os.path.join(DATA_DIR, 'bisp_socioeconomic.csv'))\n",
        "bisp_dtl = np.load(os.path.join(DATA_DIR, 'bisp_dtl_bandsRGB.npy'))\n",
        "bisp_dtl_uids = pd.read_pickle(os.path.join(DATA_DIR, 'bisp_dtl_uids_bandsRGB.pkl'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oV2-4w024iP",
        "outputId": "da149772-c903-4feb-ed00-c9a3b9674844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Subset Poverty\n",
        "bisp_pov_sub = bisp_pov[bisp_pov.year == 2014]\n",
        "bisp_pov_sub = bisp_pov_sub[bisp_pov_sub.uid.isin(bisp_dtl_uids.uid)]\n",
        "\n",
        "## Subset DTL\n",
        "keep = bisp_dtl_uids.uid.isin(bisp_pov_sub.uid)\n",
        "bisp_dtl_sub = bisp_dtl[keep]\n",
        "\n",
        "## Confirm uids same order\n",
        "(bisp_pov_sub.uid == bisp_pov_sub.uid).value_counts()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True    3372\n",
              "Name: uid, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KlUPIYb8gnw"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuCKwuARKt_E",
        "outputId": "a0f134ed-46c3-4588-8984-951b8f2a2acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "# SPLIT DATA INTO TRAINING AND TESTING\n",
        "trainX, testX, raw_trainY, raw_testY = train_test_split(bisp_dtl_sub, bisp_pov_sub['pscores'], \n",
        "                                                        test_size=0.2)\n",
        "\n",
        "\n",
        "# PREP TRAINING AND TESTING DATA\n",
        "#trainY = to_categorical(raw_trainY)\n",
        "#testY = to_categorical(raw_testY)\n",
        "\n",
        "\n",
        "#print(np.unique(NTL, return_counts=True))\n",
        "\n",
        "#print(np.unique(raw_trainY, return_counts=True))\n",
        "#print(np.unique(raw_testY, return_counts=True))\n",
        "\n",
        "#print(np.unique(trainY, return_counts=True))\n",
        "#print(np.unique(testY, return_counts=True))\n",
        "\n",
        "# PREP PIXELS IN FEATURES\n",
        "trainX, testX = normalize(trainX), normalize(testX)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-d66b951fee68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# PREP PIXELS IN FEATURES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'normalize' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh8-K6jYtyvG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr7NIkb6vWJu",
        "outputId": "21d0b23d-4b19-464a-e9ea-3629e56043ba"
      },
      "source": [
        "model_cont = define_model_imagenet_cont(image_height, image_width, N_bands, n_ntl_bins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfwxDuUEvmgm",
        "outputId": "529dc3f0-8bc1-49c7-c349-1f3ab020683a"
      },
      "source": [
        "evaluate_model(model_cont, trainX_cont, raw_trainY_cont, testX_cont, raw_testY_cont)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.66457, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.66457 to 0.61604, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.61604 to 0.59966, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.59966 to 0.59099, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59099 to 0.57950, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.57950 to 0.57843, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.57843 to 0.57657, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.57657\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.57657 to 0.56832, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.56832 to 0.56055, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.56055\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.56055 to 0.55606, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.55606\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.55606\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.55606\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.55606 to 0.55262, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.55262 to 0.55018, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.55018 to 0.54992, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.54992\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.54992 to 0.54906, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.54906 to 0.54882, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.54882 to 0.54312, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.54312 to 0.54267, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.54267\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.54267 to 0.54247, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.54247 to 0.53914, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.53914\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.53914\n",
            "                              Accuracy: 9.884352766675875e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_Pgo6zwPB-"
      },
      "source": [
        "best_model = load_model(CNN_FILENAME)\n",
        "\n",
        "### Save Dataframe of Predicted Values\n",
        "\n",
        "# Predict Values\n",
        "predY = best_model.predict(testX_cont)\n",
        "#predY = np.argmax(predY, axis = 1)\n",
        "#testY_bins = np.argmax(testY, axis = 1)\n",
        "\n",
        "# Make Dataframe\n",
        "results_df = pd.DataFrame({'predY': predY[:,0], 'testY': raw_testY_cont})\n",
        "\n",
        "# Save Dataframe\n",
        "results_df.to_csv(PREDICTION_FILENAME_CONT, index=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "G6kJKGSDxTHf",
        "outputId": "e085d561-7958-4315-e5b4-e35643c6e262"
      },
      "source": [
        "#results_df.head()\n",
        "#raw_testY_cont\n",
        "#predY\n",
        "results_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predY</th>\n",
              "      <th>testY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.517897</td>\n",
              "      <td>2.367192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.907559</td>\n",
              "      <td>8.239053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.862707</td>\n",
              "      <td>0.117567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.416992</td>\n",
              "      <td>0.217285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.380270</td>\n",
              "      <td>0.675854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      predY     testY\n",
              "0  2.517897  2.367192\n",
              "1  7.907559  8.239053\n",
              "2  3.862707  0.117567\n",
              "3 -2.416992  0.217285\n",
              "4  1.380270  0.675854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKlWDX3gLkde"
      },
      "source": [
        "## **Run Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icaSC1870guy",
        "outputId": "fb8f30b7-a978-4334-8a34-d020070fbcbe"
      },
      "source": [
        "model = define_model_imagenet(image_height, image_width, N_bands, n_ntl_bins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTt_30BEMrss",
        "outputId": "77c230f5-1e08-49e1-f4cc-805914ed0821"
      },
      "source": [
        "evaluate_model(model, trainX, trainY, testX, testY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.79896, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.79896 to 0.77657, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.77657 to 0.75853, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.75853 to 0.75729, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.75729 to 0.74811, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.74811 to 0.74748, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.74748 to 0.74441, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.74441\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.74441\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.74441 to 0.74282, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.74282\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.74282 to 0.74231, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.74231\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.74231 to 0.73789, saving model to /content/drive/My Drive/World Bank/Pakistan Poverty Estimation/Data/CNN/Nbands3_nNtlBins3_minNTLbinCount16861/script_CNN.h5\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.73789\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.73789\n",
            "                              Accuracy: 0.6896313428878784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0akMTs7NK4iJ",
        "outputId": "c0b5a714-aa52-452c-e4b0-0bb49299b931"
      },
      "source": [
        "# DISPLAY IN-DEPTH EVALUTAION METRICS\n",
        "best_model = load_model(CNN_FILENAME)\n",
        "display_eval_metrics(model, testX, testY, n_ntl_bins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Radiance Level 1       0.80      0.73      0.77      3420\n",
            "Radiance Level 2       0.63      0.68      0.66      3429\n",
            "Radiance Level 3       0.65      0.65      0.65      3268\n",
            "\n",
            "        accuracy                           0.69     10117\n",
            "       macro avg       0.69      0.69      0.69     10117\n",
            "    weighted avg       0.69      0.69      0.69     10117\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VYvJlW58z-M"
      },
      "source": [
        "### Save Dataframe of Predicted Values\n",
        "\n",
        "# Predict Values\n",
        "predY = best_model.predict(testX) # model.predict(testX)\n",
        "predY = np.argmax(predY, axis = 1)\n",
        "testY_bins = np.argmax(testY, axis = 1)\n",
        "\n",
        "# Make Dataframe\n",
        "results_df = pd.DataFrame({'predY': predY, 'testY': testY_bins})\n",
        "\n",
        "# Save Dataframe\n",
        "results_df.to_csv(PREDICTION_FILENAME, index=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_smbAxFWvWrP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUJ79Dvkvb-3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIaYzmPcvjTS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABUz9Hk8wPmd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}